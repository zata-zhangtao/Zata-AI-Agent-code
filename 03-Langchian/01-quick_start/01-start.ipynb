{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速上手示例：构建一个简单的问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object BaseChatModel.stream at 0x000001AE27B42260>\n",
      "2025年的技术趋势将聚焦以下关键领域：  \n",
      "1. **人工智能深化**：生成式AI、多模态模型进一步成熟，推动医疗、制造、教育等垂直领域应用。  \n",
      "2. **量子计算突破**：实用化进展加速，可能在药物研发、优化问题解决中实现初步商业化。  \n",
      "3. **绿色技术主导**：可再生能源、储能技术、碳捕捉及氢能技术加速落地，助力碳中和目标。  \n",
      "4. **生物技术革命**：基因编辑（如CRISPR）推动个性化医疗，合成生物学或重塑工业生产。  \n",
      "5. **扩展现实（XR）普及**：AR/VR硬件轻量化，应用场景扩展至远程协作、教育及元宇宙生态。  \n",
      "6. **边缘计算与6G**：低延迟边缘计算结合5G/6G网络，支持物联网与实时数据处理需求。  \n",
      "7. **网络安全强化**：零信任架构与AI驱动的威胁检测成为企业刚需，应对复杂攻击。  \n",
      "8. **脑机接口探索**：神经科技在医疗领域（如瘫痪治疗）展开临床应用，长期潜力显著。  \n",
      "9. **区块链与Web3**：企业级应用聚焦供应链透明化与去中心化金融（DeFi）创新。  \n",
      "\n",
      "这些趋势将共同推动社会效率提升与可持续发展，同时带来伦理与安全挑战。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化模型\n",
    "# 可以使用OpenAI的API\n",
    "# llm = ChatOpenAI(model=\"gpt-4\", api_key=\"your-openai-api-key\")\n",
    "# 或者可以用其他的API，比如阿里云的\n",
    "api_key = os.getenv(\"api_key\")\n",
    "base_url = os.getenv(\"base_url\")\n",
    "model = os.getenv(\"model\")\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url,model=model,  streaming=True)\n",
    "\n",
    "###################调用方法一########################\n",
    "result = llm.stream(\"2025年的技术趋势是什么？\")\n",
    "for chunk in result:\n",
    "    print(chunk.content, end='', flush=True)\n",
    "###################################################\n",
    "\n",
    "\n",
    "###################调用方法二##########################\n",
    "# 定义提示模板\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"请简洁回答以下问题：{question}\"\n",
    ")\n",
    "\n",
    "# 创建链\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 运行链\n",
    "question = \"2025年的技术趋势是什么？\"\n",
    "response = chain.run(question)\n",
    "print(response)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进阶功能：RAG 系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据您提供的文档内容，以下是提到的重要内容总结：\n",
      "\n",
      "---\n",
      "\n",
      "### **核心模块与功能**\n",
      "1. **模型 I/O**  \n",
      "   - 与 LLM 交互，支持 OpenAI、阿里云（如 `qwq-32b`）、Anthropic 等模型。\n",
      "   - 示例：通过 `ChatOpenAI` 初始化模型，调用 `llm.invoke()` 或 `chain.run()` 获取响应。\n",
      "\n",
      "2. **内存（Memory）**  \n",
      "   - 保存对话历史，例如 `ConversationBufferMemory` 可记住用户之前的输入。\n",
      "   - 示例：在 `ConversationChain` 中使用内存，实现多轮对话的上下文感知。\n",
      "\n",
      "3. **链（Chains）**  \n",
      "   - 组合提示、模型和逻辑，例如 `LLMChain` 处理单一流程，`SequentialChain` 连接多个链。\n",
      "   - 示例：通过 `PromptTemplate` 定义问题模板，结合模型生成回答。\n",
      "\n",
      "4. **检索（Retrieval）**  \n",
      "   - 通过向量数据库（如 FAISS 或 Qdrant）实现检索增强生成（RAG）。\n",
      "   - 示例：加载外部文档，使用 `OpenAIEmbeddings` 创建向量存储，通过 `RetrievalQA` 回答基于文档的问题。\n",
      "\n",
      "5. **代理（Agents）**  \n",
      "   - 让 LLM 动态调用工具（如维基百科搜索、计算器等）解决问题。\n",
      "   - 示例：使用 `initialize_agent` 结合 `WikipediaAPIWrapper` 获取实时信息。\n",
      "\n",
      "6. **LangGraph**  \n",
      "   - 构建复杂工作流或多代理系统，支持状态管理和节点间逻辑。\n",
      "   - 示例：定义状态和节点函数，通过 `StateGraph` 编排流程。\n",
      "\n",
      "---\n",
      "\n",
      "### **关键代码示例**\n",
      "1. **基础问答系统**  \n",
      "   ```python\n",
      "   # 使用阿里云模型\n",
      "   llm = ChatOpenAI(\n",
      "       api_key=os.getenv(\"api_key\"),\n",
      "       base_url=os.getenv(\"base_url\"),\n",
      "       model=os.getenv(\"model\"),\n",
      "       streaming=True\n",
      "   )\n",
      "   ```\n",
      "\n",
      "2. **RAG 系统**  \n",
      "   ```python\n",
      "   # 加载文档并创建向量数据库\n",
      "   documents = TextLoader(\"your_document.txt\").load()\n",
      "   vector_store = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
      "   # 创建检索链\n",
      "   qa_chain = RetrievalQA.from_chain_type(\n",
      "       llm=ChatOpenAI(),\n",
      "       chain_type=\"stuff\",\n",
      "       retriever=vector_store.as_retriever()\n",
      "   )\n",
      "   ```\n",
      "\n",
      "3. **代理示例**  \n",
      "   ```python\n",
      "   # 定义工具并初始化代理\n",
      "   tools = [Tool(name=\"Wikipedia\", func=WikipediaAPIWrapper().run, description=\"查询维基百科\")]\n",
      "   agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\")\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **资源与工具**\n",
      "- **安装命令**：`pip install langchain` 及对应模型的合作伙伴包（如 `langchain-openai`）。\n",
      "- **向量数据库**：FAISS、Qdrant、Pinecone 等。\n",
      "- **部署工具**：LangSmith（调试/监控）、LangServe（部署为 API）。\n",
      "- **社区资源**：\n",
      "  - 官网：[python.langchain.com](https://python.langchain.com)\n",
      "  - 中文社区：[www.langchain.com.cn](https://www.langchain.com.cn)\n",
      "  - GitHub：[github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\n",
      "\n",
      "---\n",
      "\n",
      "### **技术趋势（示例输出）**\n",
      "文档中提到的 2025 年技术趋势包括：\n",
      "1. 生成式 AI 的广泛应用。\n",
      "2. 量子计算实用化进展。\n",
      "3. 可持续技术（绿色能源、碳捕捉）。\n",
      "4. 扩展现实（XR）与元宇宙。\n",
      "5. 生物科技（基因编辑、合成生物学）。\n",
      "6. 物联网与边缘计算的结合。\n",
      "7. AI 驱动的网络安全。\n",
      "\n",
      "---\n",
      "\n",
      "如果需要更具体的模块或功能详解，请进一步说明！\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# 加载文档\n",
    "loader = TextLoader(\"example_doc.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "api_key = os.getenv(\"api_key\")\n",
    "base_url = os.getenv(\"base_url\")\n",
    "\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v3\",\n",
    "    dashscope_api_key=api_key,\n",
    "    # base_url=base_url\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# 初始化检索链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "     \n",
    "    llm=ChatOpenAI(api_key=api_key, base_url=base_url,model=\"qwq-32b\",streaming=True),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever()\n",
    ")\n",
    "\n",
    "# 查询\n",
    "response = qa_chain.run(\"文档中提到的重要内容是什么？\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Upick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
